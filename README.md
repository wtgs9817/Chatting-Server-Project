# Chatting-Server-Project(학습용 개인 프로젝트)
<br />

**main 브랜치** - 다중 서버 환경에서 Redis Pub/Sub를 도입하여 서버 간 메시지 동기화. 비동기 배치 저장 (5분마다 버퍼 확인 + 각 서버마다 200개 이상 시 일괄 저장)

<br />

**test-project01 브랜치** - Redis(Pub/Sub) 제외
(목적: 다중 서버 환경에서 서버 간 메시지 전달 실패 확인(Redis Pub/Sub 도입 이유 증명)

<br />

**test-project02 브랜치** - 동기 저장 방식
(목적: 비동기 배치 저장 대비 DB I/O 부하 비교)

<br /> 

**test-project03 브랜치** - 단일 채팅 서버 
(목적: 다수의 사용자가 이용할 때 다중 서버 환경의 확장성 증명)

<br /> <br />
# 👍 개선점
<br />

**서버 확장을 통한 단일 서버 성능 병목 해결 및 확장성 확보 / k6 기반 성능 검증**

실시간 트래픽 급증 상황에서 단일 서버 아키텍처가 직면하는 가용성 한계를 k6 기반 고부하 테스트를 통해 검증했습니다.(500명 / 1000명)
<br />
테스트 결과, 가상 사용자가 500명에서 1,000명으로 2배 증가했음에도 불구하고, 전체 메시지 수신량은 약 **481만 건**에서 450만 건으로 **6.5%** 감소하였고, 초당 처리량(TPS) 역시 **79,000건**에서 **73,000건**으로 약 **7.6%** 하락하는 현상을 확인했습니다.
<br />
증가하는 사용자로 인한 병목 현상이 발생하여 단일 서버 자원의 한계로 성능 저하까지 이어진 결과를 볼 수 있었습니다.
단일 아키텍처의 한계를 정확한 수치기반으로 확인하며 확장 가능한 서버 아키텍처를 구축해 향상된 결과값을 도출하는 것을 목표로 하였습니다.
<br />
단일 서버 환경을 project03 브랜치로 옮기고, main 브랜치를 통해 다중 서버 환경을 구축했습니다.
<br />
nginx를 통해 로드밸런싱하여 균일하게 사용자를 각 서버로 분배하고, 데이터 정합성을 위해 3개의 서버 모두 하나의 db로 통일했으며 docker-compose를 통해 유연하게 수평 확장이 가능하도록 구성했습니다.

k6기반 테스트 결과(1000명의 가상 사용자 단일 서버 / 1000명의 가상 사용자 다중 서버(3대)

메시지 수신량 **450만 건** --->  **1100만 건** (**144.4%**) <br />
메시지 처리량 **73,665 msgs/s** ---> **163,022msgs/s** (**121.29%**)<br />
수신 트래픽 **21mb/s** ---> **50mb/s** (**138.1%**)
<br />


향상된 결과를 확인할 수 있었고, 다중 서버 환경을 구축한 이유를 수치로 검증했습니다.

<br /> <br />

**비동기 배치 저장 / 동기 저장 성능 비교**
<br />
데이터가 들어오는 즉시 저장하는 동기 방식의 경우 DB I/O 병목을 초래하게 되고, 백엔드 성능 저하의 원인이 됩니다. 이를 정확한 수치로 확인하기 위해 project02 브랜치에 구조는 동일하게 다중 서버 환경에서 저장 방식만 동기 방식으로 구현하였습니다.
<br /> <br />
비동기 방식의 경우 ConcurrentLinkedQueue에 메시지를 저장 각 서버마다 200개의 메시지가 쌓이면 일괄 저장 <br /> 
버퍼에 메시지가 남아있을 경우를 대비하여 5분마다 확인하고 남은 메시지 처리 <br /> <br />
k6 기반 테스트 결과(1000명 동기 저장 방식/ 1000명 비동기 저장 방식)
<br />

메시지 수신량 **860만 건**---> **1100만 건**	(27.91%) 		  
메시지 처리량 **139,813 msgs/s** ---> **163,022msgs/s** (16.6%) 	<br />	
수신 트래픽 **41mb/s** ---> **50mb/s** (21.95%) 	<br />	

동기 방식의 경우 저장해야 하는 데이터량에 따라 커넥션 풀을 최소~최대까지 유지해야 합니다. 테스트 상황에서는 커넥션을 최대치까지 사용해야 했고, 이 과정에서 DB I/O 부하가 상승했습니다. 한정된 서버 자원을 DB 처리에 
사용하면서 성능 저하로 이어졌고, 비동기 방식 대비 낮은 성능을 보였습니다.

<br />

이러한 결과를 기반으로 main 브랜치에는 비동기 방식을 선택하여 적용하였습니다.

<br /> <br />

**Redis Pub/Sub을 활용한 분산 서버 간 메시지 정합성 확보**
<br />

단일 서버 환경에서는 WebSocket 연결만으로 서버 내 사용자들끼리 채팅이 가능했습니다. 하지만 서버를 확장한 뒤 같은 채팅방이라도 서버가 다르면 다른 서버의 이용자와 소통이 불가능해졌고, 이를 해결하기 위해 Redis Pub/Sub를 도입하였습니다.
<br />
Redis Publisher 클래스를 생성하여 채팅 메시지 전송용 채널을 구성하고, 해당 채널을 구독하는 모든 서버가 동일하게 메시지를 수신할 수 있도록 구현하였습니다. <br />
Subscriber 클래스에서는 채널로부터 메시지를 수신한 뒤 각 서버에 연결된 클라이언트에게 브로드캐스트하는 구조를 구축하였습니다.
 <br /> <br />

k6로 project01 브랜치(Redis Pub/Sub 미적용)와 main 브랜치(적용)에 3명의 사용자를 생성하여 각 서버(app1, app2, app3)에 1명씩 배치하고, 1분간 메시지를 전송하였습니다. <br />

project01 브랜치에서는 각 서버가 자기 서버에 연결된 사용자의 메시지만 수신하였고, 다른 서버 사용자의 메시지는 수신하지 못했습니다
<br /> <br />
서버 간 메시지 전달률: 0%
<br /> <br />
main 브랜치에서는 모든 서버가 전체 메시지를 수신하였고, Redis Pub/Sub를 통해 메시지 정합성을 확보한 것을 확인하였습니다.
<br /> <br />
서버 간 메시지 전달률: 100%


<br /> <br />

## 🧑‍💻 주요 기술 스택

### 🖼️ Frontend
- HTML / CSS / JavaScript


### 🧠 Backend
- Java
- Spring Boot 
- Spring Data JPA
- Redis pub/sub

### 🗄️ Database
- MySQL

### 🌐 인프라 / 배포
- Nginx
- Docker


### 🧰 기타 도구
- K6
- GitHub



<br /> <br />
# 프로젝트 아키텍처
<img width="3077" height="2081" alt="채팅프로젝트_아키텍처_최종" src="https://github.com/user-attachments/assets/a000c1db-f944-4cf9-a277-736cf9699524" />

<br /> <br />
# DB
<br /> 
https://www.erdcloud.com/d/zzPHfL5dZrbtexz6J
<br /><br />
<img width="1212" height="597" alt="image" src="https://github.com/user-attachments/assets/fa0e7383-36e8-4133-b414-447d5b75efc0" />
